{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "project_dir = os.path.join(os.getcwd(),'..')\n",
    "if project_dir not in sys.path:\n",
    "    sys.path.append(project_dir)\n",
    "\n",
    "attention_dir = os.path.join(project_dir, 'modules/AttentionMap')\n",
    "if attention_dir not in sys.path:\n",
    "    sys.path.append(attention_dir)\n",
    "\n",
    "sparse_dir = os.path.join(project_dir, 'modules/Sparse')\n",
    "if sparse_dir not in sys.path:\n",
    "    sys.path.append(sparse_dir) \n",
    "\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# TRAIN #################################\n",
    "import config\n",
    "root_dir = config.DATASET_DIR\n",
    "#folder = '1000-1500_dullrazor'\n",
    "folder = '4000-6000_raw'\n",
    "labels = [1,2,3,4,0]\n",
    "oimpath = []\n",
    "y = []\n",
    "impath = []\n",
    "for label in labels:\n",
    "    for name in os.listdir(os.path.join(root_dir,folder,str(label))):\n",
    "        oimpath.append(os.path.join(root_dir,folder,str(label),name))\n",
    "        impath.append(os.path.join(root_dir,str(label),name))\n",
    "    y = oimpath + [label]*len(os.listdir(os.path.join(root_dir,folder,str(label))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# TEST #################################\n",
    "import config\n",
    "root_dir = config.DATASET_DIR\n",
    "#folder = '1000-1500_dullrazor'\n",
    "folder = '4000-6000_raw'\n",
    "oimpath = []\n",
    "y = []\n",
    "impath = []\n",
    "names = os.listdir(os.path.join(root_dir,'Test',folder))\n",
    "for label in labels:\n",
    "    for name in os.listdir(os.path.join(root_dir,folder)):\n",
    "        oimpath.append(os.path.join(root_dir,folder,str(label),name))\n",
    "        impath.append(os.path.join(root_dir,str(label),name))\n",
    "    y = oimpath + [label]*len(os.listdir(os.path.join(root_dir,folder,str(label))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file1 = 'C:\\\\Users\\\\mcastro\\\\Documents\\\\MCastro\\\\2_Codigo\\\\0_DATASETS\\\\HAM10000_todo' + '\\\\' + 'ISIC2018_Task3_Test_NatureMedicine_AI_Interaction_Benefit.csv'\n",
    "metadata_1 = pd.read_csv(file1,index_col=False)\n",
    "metadata_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2 = 'C:\\\\Users\\\\mcastro\\\\Documents\\\\MCastro\\\\2_Codigo\\\\0_DATASETS\\\\HAM10000_todo' + '\\\\' + 'HAM10000_metadata.csv'\n",
    "metadata_2 = pd.read_csv(file2,index_col=False).fillna(0)\n",
    "metadata_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "diagnosis, diagnosis_n_samples = np.unique(metadata_2['dx'], return_counts=True)\n",
    "ratio = diagnosis_n_samples / diagnosis_n_samples[4]\n",
    "print(diagnosis,diagnosis[4])\n",
    "print(diagnosis_n_samples)\n",
    "print(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import DATASET_DIR\n",
    "print(DATASET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "ifile = 'C:\\\\Users\\\\mcastro\\\\Documents\\\\MCastro\\\\2_Codigo\\\\0_DATASETS\\\\HAM10000_todo\\\\HAM10000_images\\\\' + 'ISIC_0024306.jpg'\n",
    "x = Image.open(ifile).convert('RGB')\n",
    "print(x.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(oimpath),len(impath),oimpath[0],impath[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "* Dataset: 4 bigger classes in ISIC2018 (around 31000 images in those)\n",
    "* Aim: Hair removal and resizing from 4000 * 6000 to 128 * 128\n",
    "* A few copies of the \"original\" dataset are made to 128 * 128 size with and without hairs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# https://www.kaggle.com/antocad/siim-isic-image-preprocessing-dull-razor\n",
    "def dullrazor(img, lowbound=15, filterstruc=3, inpaintmat=3, showimgs=True):\n",
    "    #grayscale\n",
    "    imgtmp1 = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    #applying a blackhat\n",
    "    filterSize = (filterstruc, filterstruc)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, filterSize) \n",
    "    imgtmp2 = cv2.morphologyEx(imgtmp1, cv2.MORPH_BLACKHAT, kernel)\n",
    "    #0=skin and 255=hair\n",
    "    ret, mask = cv2.threshold(imgtmp2, lowbound, 255, cv2.THRESH_BINARY)\n",
    "    #inpainting\n",
    "    img_final = cv2.inpaint(img, mask, inpaintmat ,cv2.INPAINT_TELEA)\n",
    "\n",
    "    if showimgs:\n",
    "        print(\"_____DULLRAZOR_____\")\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        plt.imshow(img_final)\n",
    "        plt.show()\n",
    "        plt.imshow(imgtmp1, cmap=\"gray\")\n",
    "        plt.show()\n",
    "        plt.imshow(imgtmp2, cmap='gray')\n",
    "        plt.show()\n",
    "        plt.imshow(mask, cmap='gray')\n",
    "        plt.show()\n",
    "    return img_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRUEBAS PREVIAS\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms.functional import resize\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "#idx = 31252+17\n",
    "idx = 16+1+1\n",
    "#image_with_hair = Image.open(oimpath[idx])\n",
    "image_with_hair = Image.open(oimpath[idx]).convert('RGB')\n",
    "\n",
    "#size_0 = [512,768]\n",
    "size_0 = [1000,1500]\n",
    "# size_0 = [2000,3000] # No viable. Olvidate.\n",
    "image_with_hair = resize(image_with_hair,size_0)\n",
    "\n",
    "image_nohair = dullrazor(np.array(image_with_hair),lowbound=20, filterstruc=16, inpaintmat=7, showimgs=True)\n",
    "final_image = Image.fromarray(image_nohair)\n",
    "\n",
    "#size = [128,128]\n",
    "#final_image = resize(Image.fromarray(image_nohair),size)\n",
    "\n",
    "final_image.save(impath[idx])\n",
    "\n",
    "#plt.imshow(final_image)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GUARDAR IMAGENES CON LOS PARAMS ESTIMADOS ANTES\n",
    "from PIL import Image\n",
    "from torchvision.transforms.functional import resize\n",
    "\n",
    "#size_0 = [512,768]\n",
    "size_0 = [1000,1500]\n",
    "\n",
    "if size_0 == [512,768]:\n",
    "    lowbound = 20\n",
    "    filterstruc = 6\n",
    "    inpaintmat = 7\n",
    "elif size_0 == [1000,1500]:\n",
    "    lowbound = 20\n",
    "    filterstruc = 16\n",
    "    inpaintmat = 5\n",
    "\n",
    "size = [512,768]\n",
    "#size = [128,128]\n",
    "\n",
    "for i in range(len(oimpath)):\n",
    "    image = Image.open(oimpath[i]).convert('RGB')\n",
    "#    image = resize(image,size_0)\n",
    "#    image = dullrazor(np.array(image),lowbound=lowbound, filterstruc=filterstruc, inpaintmat=inpaintmat, showimgs=False)\n",
    "#    new_image = Image.fromarray(image)\n",
    "    new_image = resize(image,size)\n",
    "    new_image.save(impath[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "project_dir = os.path.join(os.getcwd(),'..')\n",
    "if project_dir not in sys.path:\n",
    "    sys.path.append(project_dir)\n",
    "\n",
    "attention_dir = os.path.join(project_dir, 'modules/AttentionMap')\n",
    "if attention_dir not in sys.path:\n",
    "    sys.path.append(attention_dir)\n",
    "\n",
    "sparse_dir = os.path.join(project_dir, 'modules/Sparse')\n",
    "if sparse_dir not in sys.path:\n",
    "    sys.path.append(sparse_dir) \n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 547 image(s) found.\n",
      "Output directory set to C:\\Users\\mcastro\\Documents\\MCastro\\2_Codigo\\0_DATASETS\\ISIC_2020\\Train\\4000-6000_raw\\1\\output."
     ]
    }
   ],
   "source": [
    "import Augmentor\n",
    "root_dir = config.DATASET_DIR\n",
    "augment_dir = os.path.join(root_dir,'ISIC_2020','Train','4000-6000_raw','1')\n",
    "p = Augmentor.Pipeline(augment_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining pipeline\n",
    "p.rotate90(probability=0.5)\n",
    "p.rotate270(probability=0.5)\n",
    "p.flip_left_right(probability=0.5)\n",
    "p.flip_top_bottom(probability=0.5)\n",
    "p.resize(probability=1.0, width=768, height=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=768x512 at 0x260AD55E1C0>: 100%|██████████| 548/548 [00:11<00:00, 49.15 Samples/s]\n"
     ]
    }
   ],
   "source": [
    "p.sample(548)\n",
    "#images, labels = p.sample(548)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5e370d1ee7207276d948e209459c44b65c9c6065829f2031da36f54906ba1431"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv_torch38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
