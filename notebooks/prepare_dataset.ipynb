{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "project_dir = os.path.join(os.getcwd(),'..')\n",
    "if project_dir not in sys.path:\n",
    "    sys.path.append(project_dir)\n",
    "\n",
    "attention_dir = os.path.join(project_dir, 'modules/AttentionMap')\n",
    "if attention_dir not in sys.path:\n",
    "    sys.path.append(attention_dir)\n",
    "\n",
    "sparse_dir = os.path.join(project_dir, 'modules/Sparse')\n",
    "if sparse_dir not in sys.path:\n",
    "    sys.path.append(sparse_dir) \n",
    "\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "root_dir = config.DATASET_DIR\n",
    "labels = [4]\n",
    "oimpath = []\n",
    "y = []\n",
    "impath = []\n",
    "for label in np.unique(labels):\n",
    "    for name in os.listdir(os.path.join(root_dir,'4000-6000_raw',str(label))):\n",
    "        oimpath.append(os.path.join(root_dir,'4000-6000_raw',str(label),name))\n",
    "        impath.append(os.path.join(root_dir,str(label),name))\n",
    "    y = oimpath + [label]*len(os.listdir(os.path.join(root_dir,'4000-6000_raw',str(label))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(oimpath),len(impath),oimpath[0],impath[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# https://www.kaggle.com/antocad/siim-isic-image-preprocessing-dull-razor\n",
    "def dullrazor(img, lowbound=15, filterstruc=3, inpaintmat=3, showimgs=True):\n",
    "    #grayscale\n",
    "    imgtmp1 = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    #applying a blackhat\n",
    "    filterSize = (filterstruc, filterstruc)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, filterSize) \n",
    "    imgtmp2 = cv2.morphologyEx(imgtmp1, cv2.MORPH_BLACKHAT, kernel)\n",
    "    #0=skin and 255=hair\n",
    "    ret, mask = cv2.threshold(imgtmp2, lowbound, 255, cv2.THRESH_BINARY)\n",
    "    #inpainting\n",
    "    img_final = cv2.inpaint(img, mask, inpaintmat ,cv2.INPAINT_TELEA)\n",
    "\n",
    "    if showimgs:\n",
    "        print(\"_____DULLRAZOR_____\")\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        plt.imshow(img_final)\n",
    "        plt.show()\n",
    "        plt.imshow(imgtmp1, cmap=\"gray\")\n",
    "        plt.show()\n",
    "        plt.imshow(imgtmp2, cmap='gray')\n",
    "        plt.show()\n",
    "        plt.imshow(mask, cmap='gray')\n",
    "        plt.show()\n",
    "    return img_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRUEBAS PREVIAS\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms.functional import resize\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "#idx = 31252+17\n",
    "idx = 16+1+1\n",
    "#image_with_hair = Image.open(oimpath[idx])\n",
    "image_with_hair = Image.open(oimpath[idx]).convert('RGB')\n",
    "\n",
    "#size_0 = [512,768]\n",
    "size_0 = [1000,1500]\n",
    "# size_0 = [2000,3000] # No viable. Olvidate.\n",
    "image_with_hair = resize(image_with_hair,size_0)\n",
    "\n",
    "image_nohair = dullrazor(np.array(image_with_hair),lowbound=20, filterstruc=16, inpaintmat=7, showimgs=True)\n",
    "final_image = Image.fromarray(image_nohair)\n",
    "\n",
    "#size = [128,128]\n",
    "#final_image = resize(Image.fromarray(image_nohair),size)\n",
    "\n",
    "final_image.save(impath[idx])\n",
    "\n",
    "#plt.imshow(final_image)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GUARDAR IMAGENES CON LOS PARAMS ESTIMADOS ANTES\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision.transforms.functional import resize\n",
    "\n",
    "size = [128,128]\n",
    "\n",
    "#size_0 = [512,768]\n",
    "size_0 = [1000,1500]\n",
    "\n",
    "if size_0 == [512,768]:\n",
    "    lowbound = 20\n",
    "    filterstruc = 6\n",
    "    inpaintmat = 7\n",
    "elif size_0 == [1000,1500]:\n",
    "    lowbound = 20\n",
    "    filterstruc = 16\n",
    "    inpaintmat = 5\n",
    "\n",
    "\n",
    "for i in range(len(oimpath)):\n",
    "    image = Image.open(oimpath[i]).convert('RGB')\n",
    "    image = resize(image,size_0)\n",
    "    image = dullrazor(np.array(image),lowbound=lowbound, filterstruc=filterstruc, inpaintmat=inpaintmat, showimgs=False)\n",
    "    new_image = Image.fromarray(image)\n",
    "#    new_image = resize(image,size)\n",
    "    new_image.save(impath[i])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5e370d1ee7207276d948e209459c44b65c9c6065829f2031da36f54906ba1431"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv_torch38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
