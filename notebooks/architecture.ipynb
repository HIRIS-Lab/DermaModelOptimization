{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys\n",
    "project_dir = os.path.join(os.getcwd(),'..')\n",
    "if project_dir not in sys.path:\n",
    "    sys.path.append(project_dir)\n",
    "\n",
    "attention_dir = os.path.join(project_dir, 'modules/AttentionMap')\n",
    "if attention_dir not in sys.path:\n",
    "    sys.path.append(attention_dir)\n",
    "\n",
    "sparse_dir = os.path.join(project_dir, 'modules/Sparse')\n",
    "if sparse_dir not in sys.path:\n",
    "    sys.path.append(sparse_dir) \n",
    "\n",
    "import config\n",
    "from derma.dataset import Derma\n",
    "from derma.architecture import InvertedResidual\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import MobileNetV2\n",
    "from torchvision import transforms\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = 4  # 1: MbV2, 2: MbV2_CA, 3: MbV2_CA_Reduced, 4: MbV2_Reduced\n",
    "\n",
    "DB_used = 'ISIC2019' # 'HAM10000', 'ISIC2019', 'PH2'\n",
    "\n",
    "save_splited_images = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OTHER PARAMS\n",
    "\n",
    "inverted_residual_setting_v0 = [\n",
    "        # t, c, n, s\n",
    "        [1, 16, 1, 1],\n",
    "        [6, 24, 2, 2],\n",
    "        [6, 32, 3, 2],\n",
    "        [6, 64, 4, 2],\n",
    "        [6, 96, 3, 1],\n",
    "        [6, 160, 3, 2],\n",
    "        [6, 320, 1, 1],\n",
    "    ] #ORIGINAL\n",
    "\n",
    "inverted_residual_setting_vT3 = [\n",
    "        # t, c, n, s\n",
    "        [1, 16, 1, 1],\n",
    "        [4, 24, 1, 2],\n",
    "        [4, 32, 1, 2],\n",
    "        [4, 64, 1, 2],\n",
    "        [4, 96, 1, 1],\n",
    "        [4, 160, 1, 2],\n",
    "        [4, 320, 1, 1],\n",
    "    ]\n",
    "\n",
    "lr = 1e-4\n",
    "n_epoch = 20\n",
    "batch_size = 40\n",
    "\n",
    "if test == 1:\n",
    "    Test = 'MbV2'\n",
    "    CoordAtt = False\n",
    "    inverted_residual_setting = inverted_residual_setting_v0\n",
    "elif test == 2:\n",
    "    Test = 'MbV2_CA'\n",
    "    CoordAtt = True\n",
    "    inverted_residual_setting = inverted_residual_setting_v0\n",
    "elif test == 3:\n",
    "    Test = 'MbV2_CA_Reduced'\n",
    "    CoordAtt = True\n",
    "    inverted_residual_setting = inverted_residual_setting_vT3\n",
    "elif test == 4:\n",
    "    Test = 'MbV2_Reduced'\n",
    "    CoordAtt = False\n",
    "    inverted_residual_setting = inverted_residual_setting_vT3\n",
    "\n",
    "if DB_used == 'HAM10000':\n",
    "    dataset_dir = os.path.join(config.DATASET_DIR,'HAM10000_splited')\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((256, 256))\n",
    "    ])\n",
    "    transform_flip = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip()\n",
    "    ])\n",
    "elif DB_used == 'ISIC2019':\n",
    "    dataset_dir = os.path.join(config.DATASET_DIR,'ISIC2019_splited')\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    transform_flip = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip()\n",
    "    ])\n",
    "elif DB_used == 'PH2':\n",
    "    dataset_dir = os.path.join(config.DATASET_DIR,'PH2_up_splited')\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((256, 256))\n",
    "    ])\n",
    "    transform_flip = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip()\n",
    "    ])\n",
    "    lr = 5e-5\n",
    "    batch_size = 6\n",
    "\n",
    "\n",
    "CIFAR_dir = os.path.join(config.RESULT_DIR,'weights',Test,'features.pth')\n",
    "log_dir = os.path.join(config.RESULT_DIR,'log',Test,DB_used) \n",
    "model_dir = os.path.join(config.RESULT_DIR,'weights',Test,DB_used,'model.pth')\n",
    "\n",
    "labels = [0, 1]\n",
    "split_ratio = [0.8,0.1,0.1] # train, val, test\n",
    "Weighted_sampling = True\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_splited_images:\n",
    "    dataset = Derma(dataset_dir,labels=labels,transform=transform_flip)\n",
    "    train_set, val_set, test_set = dataset.split_rand(split_ratio)\n",
    "else:\n",
    "    train_set = Derma(os.path.join(dataset_dir,'train'),labels=labels,transform=transform_flip)\n",
    "    val_set = Derma(os.path.join(dataset_dir,'val'),labels=labels,transform=transform)\n",
    "    test_set = Derma(os.path.join(dataset_dir,'test'),labels=labels,transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples per class: [3589 3646]\n",
      "Weight per class: [0.00027863 0.00027427]\n",
      "Samples per class: [483 421]\n",
      "Weight per class: [0.00207039 0.0023753 ]\n",
      "Samples per class: [450 455]\n",
      "Weight per class: [0.00222222 0.0021978 ]\n"
     ]
    }
   ],
   "source": [
    "# Weighted sampling\n",
    "if Weighted_sampling:\n",
    "    from derma.dataset import get_samples_weight\n",
    "    train_sampler, train_weights = get_samples_weight(train_set)\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, num_workers=0, sampler=train_sampler, shuffle=False)\n",
    "    val_sampler, val_weights = get_samples_weight(val_set)\n",
    "    val_loader = DataLoader(val_set, batch_size=batch_size, num_workers=0, sampler=val_sampler, shuffle=False)\n",
    "    test_sampler, test_weights = get_samples_weight(test_set)\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, num_workers=0, sampler=test_sampler, shuffle=False)\n",
    "else:\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_splited_images:\n",
    "    from PIL import Image\n",
    "    from torchvision.transforms.functional import resize\n",
    "    for folder in ['train','val','test']:\n",
    "        names = dataset.getnames()\n",
    "        y = dataset.get_labels()\n",
    "        if folder == 'train':\n",
    "            indexes = train_loader.dataset.indices\n",
    "        elif folder == 'val':\n",
    "            indexes = val_loader.dataset.indices\n",
    "        elif folder == 'test':\n",
    "            indexes = test_loader.dataset.indices\n",
    "        path_base = os.path.join(dataset_dir,folder)\n",
    "        for i in indexes:\n",
    "            _, image_name = os.path.split(names[i])\n",
    "            image = Image.open(names[i]).convert('RGB')\n",
    "            image = resize(image,[256,256])\n",
    "            image.save(os.path.join(path_base,str(int(y[i])),image_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CoordAtt:\n",
    "    model = MobileNetV2(num_classes=len(labels), inverted_residual_setting=inverted_residual_setting, block=InvertedResidual)\n",
    "else:\n",
    "    model = MobileNetV2(num_classes=len(labels), inverted_residual_setting=inverted_residual_setting) # standard MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LOADIONG CIFAR WEIGHTS\n",
    "features = torch.load(CIFAR_dir)\n",
    "model.features.load_state_dict(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [09:25<00:00, 28.29s/epoch, acc=0.8015, tls=0.4274]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.418884444495906"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from derma.utils import train\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "tb_writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "train(model, [train_loader,val_loader], optimizer, criterion, n_epoch, tb_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.features.state_dict(),model_dir) # Hay que guardar *todo*\n",
    "torch.save(model.state_dict(),model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    model.load_state_dict(torch.load(model_dir))\n",
    "    model.to(device)\n",
    "else:\n",
    "    model.load_state_dict(torch.load(model_dir),map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precission</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sensitivity  Specificity  Precission  Recall  Accuracy\n",
       "0        0.875     0.764706    0.636364   0.875       0.8"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from derma.experiment import test_experiment\n",
    "metrics_df = test_experiment(model,test_loader)\n",
    "metrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bc81a3ec444beb1d5a523daf231afa571e79be8a57abb6fe0028623a3d4d7136"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('HySpecLab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
